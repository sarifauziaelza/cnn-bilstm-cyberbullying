import os
import pickle
import re
import numpy as np
import pandas as pd
from flask import Flask, render_template, request
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
from sklearn.metrics import classification_report, confusion_matrix, roc_curve

# === KONFIGURASI MODEL & TOKENIZER ===
MODEL_PATH = "CNNBiLSTM_fasttext_300_FAIR.h5"
TOKENIZER_PATH = "tokenizer_fasttext.pkl"
MAX_LEN = 55  # Sesuai saat training
DEFAULT_THRESHOLD = 0.47  # Default jika tidak pakai ROC

# === FUNGSI PREPROCESSING ===
def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-z0-9\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

# === LOAD MODEL & TOKENIZER ===
model = load_model(MODEL_PATH)
with open(TOKENIZER_PATH, "rb") as f:
    tokenizer = pickle.load(f)

# === SETUP FLASK ===
app = Flask(__name__)

# === HOMEPAGE ===
@app.route("/", methods=["GET", "POST"])
def index():
    predictions = None
    total_data = None
    jumlah_salah = None
    akurasi_prediksi = None
    error = None

    if request.method == "POST":
        file = request.files["file"]
        if file:
            try:
                df = pd.read_excel(file, engine="openpyxl")  # safer for .xlsx
            except:
                try:
                    df = pd.read_excel(file)  # fallback
                except Exception as e:
                    return render_template("index.html", error=f"Gagal membaca file: {e}")

            if "text" not in df.columns:
                return render_template("index.html", error="Kolom 'text' tidak ditemukan.")

            texts = df["text"].astype(str).apply(clean_text).tolist()
            sequences = tokenizer.texts_to_sequences(texts)
            padded = pad_sequences(sequences, maxlen=MAX_LEN)
            probs = model.predict(padded)

            # Hitung threshold optimal jika ada kolom label
            if "label" in df.columns:
                true_labels = df["label"].astype(int).values
                fpr, tpr, thresholds = roc_curve(true_labels, probs)
                optimal_idx = (tpr - fpr).argmax()
                threshold_to_use = thresholds[optimal_idx]
                print(f"ðŸ“Œ Threshold ROC optimal: {round(threshold_to_use, 4)}")
            else:
                threshold_to_use = DEFAULT_THRESHOLD

            labels = (probs >= threshold_to_use).astype(int).flatten()
            df["Predicted_Label"] = labels
            df["Probability"] = probs.flatten()
            df["Class"] = df["Predicted_Label"].map({1: "Non-Cyberbullying", 0: "Cyberbullying"})

            predictions = df[["text", "Class", "Probability"]].values.tolist()
            total_data = len(df)

            if "label" in df.columns:
                jumlah_salah = int((labels != true_labels).sum())
                akurasi_prediksi = round((1 - jumlah_salah / total_data) * 100, 2)

                print("\n=== Classification Report ===")
                print(classification_report(true_labels, labels))
                print("\n=== Confusion Matrix ===")
                print(confusion_matrix(true_labels, labels))
            else:
                error = "Kolom 'label' tidak ditemukan, akurasi tidak dihitung."

    return render_template("index.html",
                           predictions=predictions,
                           total_data=total_data,
                           jumlah_salah=jumlah_salah,
                           akurasi_prediksi=akurasi_prediksi,
                           error=error)

# === JALANKAN APLIKASI ===
if __name__ == "__main__":
    app.run(debug=True)
